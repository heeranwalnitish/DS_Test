{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report, roc_curve\n",
    "from sklearn.metrics import roc_auc_score, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.read_csv(\"Training/X_train.csv\")\n",
    "train_y = pd.read_csv(\"Training/y_train.csv\")\n",
    "TEST_X = pd .read_csv(\"Test/X_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(train_X, train_y, on= \"Unique_ID\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting boolean to integer\n",
    "df.C8 = df.C8.replace({True: 1, False: 0})\n",
    "df.C6 = df.C6.replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N32                   81.180030\n",
       "N27                   81.025719\n",
       "N31                   81.025719\n",
       "N26                   81.025719\n",
       "N29                   81.025719\n",
       "N30                   81.025719\n",
       "N28                   81.025719\n",
       "N25                   81.025719\n",
       "N12                   13.960666\n",
       "N2                    13.954614\n",
       "N4                    13.936460\n",
       "N5                    13.936460\n",
       "N18                   13.936460\n",
       "N17                   13.936460\n",
       "N16                   13.936460\n",
       "N20                   13.830560\n",
       "N21                   13.830560\n",
       "N19                   13.830560\n",
       "N22                   13.830560\n",
       "N23                    7.521936\n",
       "N11                    2.166415\n",
       "N14                    1.839637\n",
       "N10.1                  1.291982\n",
       "N10                    1.291982\n",
       "N15                    1.291982\n",
       "N7                     1.291982\n",
       "N35                    1.291982\n",
       "N6                     1.104387\n",
       "N3                     1.104387\n",
       "N24                    0.000000\n",
       "N33                    0.000000\n",
       "N34                    0.000000\n",
       "Unique_ID              0.000000\n",
       "C1                     0.000000\n",
       "N9                     0.000000\n",
       "N8                     0.000000\n",
       "N1                     0.000000\n",
       "C8                     0.000000\n",
       "C7                     0.000000\n",
       "C6                     0.000000\n",
       "C5                     0.000000\n",
       "C4                     0.000000\n",
       "C3                     0.000000\n",
       "C2                     0.000000\n",
       "Dependent_Variable     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_value_percent_per_col = df.isna().sum().sort_values(ascending = False)/df.shape[0]*100\n",
    "missing_value_percent_per_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop a column having null percentage more than 80 percent\n",
    "df.drop(['N32', 'N25', 'N31','N30','N29', 'N28', 'N27','N26'], axis = 1, inplace = True)\n",
    "df.drop(['Unique_ID'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categotical variables to str\n",
    "df[['C1','C2','C3','C4','C5','C6','C7','C8']] = df[['C1','C2','C3','C4','C5','C6','C7','C8']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33050 entries, 0 to 33049\n",
      "Data columns (total 36 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   C1                  33050 non-null  object \n",
      " 1   C2                  33050 non-null  object \n",
      " 2   C3                  33050 non-null  object \n",
      " 3   C4                  33050 non-null  object \n",
      " 4   C5                  33050 non-null  object \n",
      " 5   C6                  33050 non-null  object \n",
      " 6   C7                  33050 non-null  object \n",
      " 7   C8                  33050 non-null  object \n",
      " 8   N1                  33050 non-null  float64\n",
      " 9   N2                  28438 non-null  float64\n",
      " 10  N3                  32685 non-null  float64\n",
      " 11  N4                  28444 non-null  float64\n",
      " 12  N5                  28444 non-null  float64\n",
      " 13  N6                  32685 non-null  float64\n",
      " 14  N7                  32623 non-null  float64\n",
      " 15  N8                  33050 non-null  int64  \n",
      " 16  N9                  33050 non-null  int64  \n",
      " 17  N10                 32623 non-null  float64\n",
      " 18  N10.1               32623 non-null  float64\n",
      " 19  N11                 32334 non-null  float64\n",
      " 20  N12                 28436 non-null  float64\n",
      " 21  N14                 32442 non-null  float64\n",
      " 22  N15                 32623 non-null  float64\n",
      " 23  N16                 28444 non-null  float64\n",
      " 24  N17                 28444 non-null  float64\n",
      " 25  N18                 28444 non-null  float64\n",
      " 26  N19                 28479 non-null  float64\n",
      " 27  N20                 28479 non-null  float64\n",
      " 28  N21                 28479 non-null  float64\n",
      " 29  N22                 28479 non-null  float64\n",
      " 30  N23                 30564 non-null  float64\n",
      " 31  N24                 33050 non-null  float64\n",
      " 32  N33                 33050 non-null  float64\n",
      " 33  N34                 33050 non-null  float64\n",
      " 34  N35                 32623 non-null  float64\n",
      " 35  Dependent_Variable  33050 non-null  int64  \n",
      "dtypes: float64(25), int64(3), object(8)\n",
      "memory usage: 9.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Dependent_Variable', axis=1)\n",
    "y = df['Dependent_Variable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_index = [X.columns.get_loc(i) for i in X.columns if X[i].isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple imputer\n",
    "preprocessor_1 = ColumnTransformer(\n",
    "    [\n",
    "        (\"SimpleImputer\", SimpleImputer(missing_values=np.nan, strategy='median'),null_index)\n",
    "    ], remainder = 'passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"Imputer\", preprocessor_1),\n",
    "      \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dependent_Variable\n",
       "0    22844\n",
       "1    10206\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26440, 35), (6610, 35))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, stratify = y, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = pipe.fit_transform(X_train)\n",
    "X_test_new = pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26440, 35), (6610, 35))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new.shape, X_test_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dependent_Variable\n",
       "0    18275\n",
       "1     8165\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and Evaluate function to give all metrics after model training\n",
    "def evaluate_model(true, predicted, proba):\n",
    "    cm = confusion_matrix(true, predicted)\n",
    "    accuracy = accuracy_score(true, predicted)\n",
    "    clf_report = classification_report(true, predicted)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(true, proba, pos_label=1)\n",
    "    auc_algo =  auc(fpr, tpr)\n",
    "\n",
    "    return cm, accuracy, clf_report, auc_algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2660a563880>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(\n",
    "    iterations=10000,\n",
    "    depth=3,\n",
    "    rsm=0.2,\n",
    "    verbose=False,\n",
    "    l2_leaf_reg=5,\n",
    "    class_weights={0:1,1:3},\n",
    "    min_child_samples= 50,)\n",
    "    \n",
    "model.fit(X_train_new, y_train) # Train model\n",
    "# Make predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train_new)\n",
    "y_test_pred = model.predict(X_test_new)\n",
    "y_test_pred_proba = model.predict_proba(X_test_new)[:,1]\n",
    "y_train_pred_proba = model.predict_proba(X_train_new)[:,1]\n",
    "# Evaluate Train and Test dataset\n",
    "model_train_cm , model_train_accuracy, model_train_clf, model_train_auc_score = evaluate_model(y_train, y_train_pred,y_train_pred_proba)\n",
    "model_test_cm , model_test_accuracy, model_test_clf, model_test_auc_score= evaluate_model(y_test, y_test_pred,y_test_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- CONFUSION MATRIX: [[12848  5427]\n",
      " [  861  7304]]\n",
      "- Accuracy: 0.7622\n",
      "- Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.70      0.80     18275\n",
      "           1       0.57      0.89      0.70      8165\n",
      "\n",
      "    accuracy                           0.76     26440\n",
      "   macro avg       0.76      0.80      0.75     26440\n",
      "weighted avg       0.82      0.76      0.77     26440\n",
      "\n",
      "- AUC Score: 0.8926\n"
     ]
    }
   ],
   "source": [
    "#Training data\n",
    "print('Model performance for Training set')\n",
    "print(f\"- CONFUSION MATRIX: {model_train_cm}\")\n",
    "print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "print(f\"- Classification Report: {model_train_clf}\")\n",
    "print(\"- AUC Score: {:.4f}\".format(model_train_auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- CONFUSION MATRIX: [[2910 1659]\n",
      " [ 512 1529]]\n",
      "- Accuracy: 0.6716\n",
      "- Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.64      0.73      4569\n",
      "           1       0.48      0.75      0.58      2041\n",
      "\n",
      "    accuracy                           0.67      6610\n",
      "   macro avg       0.66      0.69      0.66      6610\n",
      "weighted avg       0.74      0.67      0.68      6610\n",
      "\n",
      "- AUC Score: 0.7707\n"
     ]
    }
   ],
   "source": [
    "# Validation Data\n",
    "print(f\"- CONFUSION MATRIX: {model_test_cm}\")\n",
    "print(\"- Accuracy: {:.4f}\".format(model_test_accuracy))\n",
    "print(f\"- Classification Report: {model_test_clf}\")\n",
    "print(\"- AUC Score: {:.4f}\".format(model_test_auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Same fot the TEST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting boolean to integer\n",
    "TEST_X.C8 = df.C8.replace({True: 1, False: 0})\n",
    "TEST_X.C6 = df.C6.replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving unique ID\n",
    "uni_id = TEST_X[\"Unique_ID\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop a column having null percentage more than 80 percent\n",
    "TEST_X.drop(['N32', 'N25', 'N31','N30','N29', 'N28', 'N27','N26'], axis = 1, inplace = True)\n",
    "TEST_X.drop(['Unique_ID'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categotical variables to str\n",
    "TEST_X[['C1','C2','C3','C4','C5','C6','C7','C8']] = TEST_X[['C1','C2','C3','C4','C5','C6','C7','C8']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11017, 35)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TEST = pipe.transform(TEST_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_TEST_pred = model.predict(X_TEST)\n",
    "y_TEST_pred_proba = model.predict_proba(X_TEST)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9973138882680095"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_TEST_pred_proba.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({\n",
    "    \"Unique_ID\": uni_id,\n",
    "    \"Class_1_Probability\" : y_TEST_pred_proba\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"final_prediction.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
